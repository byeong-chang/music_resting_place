{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 원본 데이터 병합, 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 웰니스 대화 스크립트 데이터셋(train/valid set)\n",
    "# https://aihub.or.kr/aihubdata/data/view.do?currMenu=120&topMenu=100&aihubDataSe=extrldata&dataSetSn=267\n",
    "df1 = pd.read_excel('./data/감성대화말뭉치(최종데이터)_Training.xlsx')[['감정_대분류', '사람문장1', '사람문장2', '사람문장3']]\n",
    "df2 = pd.read_excel('./data/감성대화말뭉치(최종데이터)_Validation.xlsx')[['감정_대분류', '사람문장1', '사람문장2', '사람문장3']]\n",
    "\n",
    "# 노년층 대상 감성 분류 모델\n",
    "# https://aihub.or.kr/aihubdata/data/view.do?currMenu=&topMenu=&dataSetSn=453&aihubDataSe=extrldata\n",
    "df3 = pd.read_csv('./data/train.csv')[['감정_대분류', '사람문장1', '사람문장2', '사람문장3']]\n",
    "\n",
    "# 모든 데이터 결합\n",
    "df = pd.concat([df1,df2,df3])\n",
    "\n",
    "# 널값 ''로 채우기\n",
    "df = df.fillna('')\n",
    "\n",
    "# 사람문장1, 사람문장2, 사람문장3 전부 더해서 'Q' 컬럼 생성\n",
    "df['Q'] = df.apply(lambda x : x['사람문장1'] + ' ' + x['사람문장2'] + ' ' + x['사람문장3'], axis = 1)\n",
    "\n",
    "# 필요 컬럼 생성, 리네임\n",
    "df = df[['감정_대분류','Q']]\n",
    "df.columns = ['emotion', 'Q']\n",
    "\n",
    "# 당황 제외\n",
    "df = df[df['emotion'] != '당황']\n",
    "\n",
    "# 라벨 인코더 활용 emotion 라벨화\n",
    "le = LabelEncoder()\n",
    "df['emotion_label'] = le.fit_transform(df['emotion'])\n",
    "\n",
    "# 데이터프레임 인덱스 리셋, 중복 제거\n",
    "df.reset_index(drop = True, inplace = True)\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# 저장\n",
    "df.to_csv('./data/감성대화최종.csv', index = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 챗봇 데이터 증폭기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "df = pd.read_csv('C:/PlayData/Emotional_DJ_chatbot/data/wellness_dataset_original_LAST.csv', encoding = 'cp949')\n",
    "\n",
    "# 챗봇 데이터 증폭기\n",
    "# 빈 데이터를 같은 구분 값의 랜덤 값으로 넣어줌\n",
    "\n",
    "next_df = df.loc[df['구분'] == '증상/불면', '챗봇']\n",
    "answer_list = list(next_df[next_df.isna() == False])\n",
    "for idx in next_df[next_df.isna() == True].index:\n",
    "    df.loc[idx, '챗봇']= answer_list[random.randrange(0,len(answer_list))]\n",
    "    \n",
    "df.columns = ['구분', 'Q', 'A']\n",
    "df.to_csv('./data/WellNese_Preprocess_LAST.csv', index = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# json 추출 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# json 파일 접근\n",
    "with open('./data/감성대화말뭉치(최종데이터)_Training.json') as f:\n",
    "    js = json.loads(f.read())\n",
    "\n",
    "# 감정분류\n",
    "def emotion_clf(code):\n",
    "    if code == 1:\n",
    "        return '분노'\n",
    "    elif code == 2:\n",
    "        return '슬픔'\n",
    "    elif code == 3:\n",
    "        return '불안'\n",
    "    elif code == 4:\n",
    "        return '상처'\n",
    "    elif code == 5:\n",
    "        return '기쁨'\n",
    "    elif code == 6:\n",
    "        return '당황'\n",
    "\n",
    "\n",
    "# 원하는 값 Q, emotion 리스트에 저장\n",
    "Q = []\n",
    "emotion = []\n",
    "for i in range(len(js)):\n",
    "    Q.append(js[i]['talk']['content']['HS01'])\n",
    "    emotion.append(int(js[i]['profile']['emotion']['emotion-id'][-2:-1]))\n",
    "\n",
    "# Q, emotion 리스트로 데이터프레임 만들기\n",
    "new_data = pd.DataFrame(data = list(zip(Q , emotion)), columns = ['Q', 'emotion'])\n",
    "\n",
    "# 감정 분류\n",
    "new_data['emotion_kor'] = new_data['emotion'].apply(emotion_clf)\n",
    "new_data\n",
    "\n",
    "# 저장\n",
    "new_data.to_csv('감정분류텍스트.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
